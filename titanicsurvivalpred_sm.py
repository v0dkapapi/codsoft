# -*- coding: utf-8 -*-
"""titanicsurvivalpred_sm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/v0dkapapi/82056dd7a0a3449c2f3bfdbf75d302d0/titanicsurvivalpred_sm.ipynb
"""

# Importing the important libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

from google.colab import drive
drive.mount("/content/drive/")

# Uploading the downloaded Kaggle Dataset into the workspace
df_t = pd.read_csv("/content/drive/MyDrive/Titanic-Dataset.csv")
print(df_t)

df_t.head()

# Handling the Missing Values
# Dropping rows with missing Embarked values
df_t = df_t.dropna(subset=["Embarked"])
# Fill missing Age values with mean
df_t["Age"].fillna(df_t["Age"].mean(), inplace=True)

# Seperation of the Features and Final variable
y = df_t["Survived"]
X = df_t[["Pclass", "Sex", "Age", "SibSp", "Parch", "Embarked"]]

# Performing One-Hot Encoding For all the Categorical Features
encoder = OneHotEncoder(handle_unknown='ignore')
X = encoder.fit_transform(X).toarray()

# Splitting of Data into Training and Testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Creation and Training of the model using Random Forest Classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Making Predictions on Testing Set
predictions = model.predict(X_test)

# Evaluation of model's performance
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)